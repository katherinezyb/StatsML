data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:5,
data=sim.data.train$data.train,
x.test=x.test)
true.f <- function(x) {
f.out <- (x-5)*(x-12)
return(f.out)
}
true.f(16)
sim.training <- function(x.test=c(16)
) {
# Hard-coded sample size and standard deviation
n <- 20
sd.error <- 20
# Training x vector
x <- seq(4,20,length=n)
# Simulate training Y based on f(x) and normal error
y <- true.f(x)+rnorm(n,sd=sd.error)
# Simulate test case
y.test <- true.f(x.test)+rnorm(length(x.test),sd=sd.error)
# Return a list of two entries:
# 1) the dataframe data.train
# 2) test respone vector y_0
return(list(data.train=data.frame(x=x,y=y),
y.test=y.test))
}
# Simulate data
set.seed(1)
x.test <- c(10,16)
sim.data.train <- sim.training(x.test=x.test)
head(sim.data.train$data.train,4)
sim.data.train$y.test
# Plot simulated data
x.plot <- seq(4,20,by=.01)
x <- sim.data.train$data.train$x
y <- sim.data.train$data.train$y
plot(x,y,main="Simulated Data")
# Plot f(x)
lines(x.plot,true.f(x.plot),lwd=2,col="red")
# Plot test cases
y.test <- sim.data.train$y.test
abline(v=x.test,col="grey")
points(x.test,y.test,pch=20,cex=1.5,col="blue")
# Legend
legend("topleft",legend=c("f(x)","Test cases"),fill=c("red","blue"),cex=.5)
predict.test.case <- function(degree,
data,
x.test) {
# Train model
model <- lm(y~poly(x,degree=degree),data=data)
# Predict test cases
y.test.hat <- predict(model,newdata=data.frame(x=x.test))
# Return y test case
return(y.test.hat)
}
x.plot <- seq(4,20,by=.01)
x.test <- c(10,16)
# Predict for degree=1
y.pred.1 <- predict.test.case(degree=1,
data=sim.data.train$data.train,
x.test=x.test)
y.plot.1 <- predict.test.case(degree=1,
data=sim.data.train$data.train,
x.test=x.plot)
# Predict for degree=2
y.pred.2 <- predict.test.case(degree=2,
data=sim.data.train$data.train,
x.test=x.test)
y.plot.2 <- predict.test.case(degree=2,
data=sim.data.train$data.train,
x.test=x.plot)
# Predict for degree=3
y.pred.3 <- predict.test.case(degree=3,
data=sim.data.train$data.train,
x.test=x.test)
y.plot.3 <- predict.test.case(degree=3,
data=sim.data.train$data.train,
x.test=x.plot)
# Plot simulated data
x <- sim.data.train$data.train$x
y <- sim.data.train$data.train$y
plot(x,y,main="Simulated Data")
abline(h=0,lty=2)
# Plot f(x)
lines(x.plot,true.f(x.plot),lwd=1.5,col="red")
# Plot the estimated curves
lines(x.plot,y.plot.1,lwd=1.5,col="green")
lines(x.plot,y.plot.2,lwd=1.5,col="purple")
lines(x.plot,y.plot.3,lwd=1.5,col="orange")
# Plot test cases
y.test <- sim.data.train$y.test
abline(v=x.test,col="grey")
points(x.test,y.test,pch=20,cex=1.5,col="blue")
# Plot estimated test cases
points(x.test,y.pred.1,pch=20,cex=1.5,col="green")
points(x.test,y.pred.2,pch=20,cex=1.5,col="purple")
points(x.test,y.pred.3,pch=20,cex=1.5,col="orange")
# Legend
legend("topleft",
legend=c("f(x)","Test Case","Degree 1","Degree 2","Degree 3"),
fill=c("red","blue","green","purple","orange"),
cex=.5)
poly.predict <- function(degree.vec,
data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:5,
data=sim.data.train$data.train,
x.test=x.test)
poly.predict <- function(degree.vec,
data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:4,
data=sim.data.train$data.train,
x.test=x.test)
poly.predict <- function(degree.vec,
data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:4,
data=sim.data.train$data.train,
x.test=c(10))
poly.predict <- function(degree.vec,
data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:4,
data=sim.data.train$data.train,
x.test=c(10,16))
# Solution goes here -----------
poly.predict(degree.vec = 1:5,
data = sim.training(c(10)$data.train),
x.test = c(10))
# Solution goes here -----------
poly.predict(degree.vec = 1:5,
data = sim.training(c(10))$data.train,
x.test = c(10))
poly.predict <- function(degree.vec,
data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
# rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:4,
data=sim.data.train$data.train,
x.test=x.test)
poly.predict <- function(degree.vec,
data,
x.test) {
# Vectorize predict.test.case()
pred <- sapply(degree.vec,
predict.test.case,
data=data,
x.test=x.test)
# Name rows and columns
rownames(pred)  <- paste("TestCase",1:length(x.test),sep="")
colnames(pred)  <- paste("D",degree.vec,sep="")
# Return
return(pred)
}
# Test function poly.predict()
x.test <- c(10,16)
poly.predict(degree.vec=1:4,
data=sim.data.train$data.train,
x.test=x.test)
# Solution goes here -----------
mat.pred.1<-matrix(0,1000,5)
mat.pred.2<-matrix(0,1000,5)
y.test.mat<-matrix(0,1000,2)
for (i in 1:1000) {
sim.data.train<-sim.training(x.test)
poly.predict.mat<-poly.predict(degree.vec = 1:5,
data = sim.data.train$data.train,
x.test = x.test)
mat.pred.1[i,]<-poly.predict.mat[1,]
mat.pred.2[i,]<-poly.predict.mat[2,]
y.test.mat[i,]<-sim.data.train$y.test
}
mat.pred.1[1:3,]
mat.pred.2[1:3,]
y.test.mat[1:3,]
# Solution goes here -----------
varx1<-c(0,0,0,0,0)
varx2<-c(0,0,0,0,0)
biasx1<-c(0,0,0,0,0)
biasx2<-c(0,0,0,0,0)
msex1<-c(0,0,0,0,0)
msex2<-c(0,0,0,0,0)
for (i in 1:5) {
varx1[i]<-var(mat.pred.1[,i])
varx2[i]<-var(mat.pred.2[,i])
biasx1[i]<-(mean(mat.pred.1[,i])-true.f(10))^2
biasx2[i]<-(mean(mat.pred.2[,i])-true.f(16))^2
msex1[i]<-sum((y.test.mat[,1]-mat.pred.1[,i])^2)/1000
msex2[i]<-sum((y.test.mat[,2]-mat.pred.2[,i])^2)/1000
}
varx1
varx2
biasx1
biasx2
msex1
msex2
# Solution goes here -----------
var1<-c(0,0,0,0,0)
var2<-c(0,0,0,0,0)
bias1<-c(0,0,0,0,0)
bias2<-c(0,0,0,0,0)
mse1<-c(0,0,0,0,0)
mse2<-c(0,0,0,0,0)
for (i in 1:5) {
var1[i]<-var(mat.pred.1[,i])
var2[i]<-var(mat.pred.2[,i])
bias1[i]<-(mean(mat.pred.1[,i])-true.f(10))^2
bias2[i]<-(mean(mat.pred.2[,i])-true.f(16))^2
mse1[i]<-sum((y.test.mat[,1]-mat.pred.1[,i])^2)/1000
mse2[i]<-sum((y.test.mat[,2]-mat.pred.2[,i])^2)/1000
}
var1
var2
bias1
bias2
mse1
mse2
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,bias1,mse1),max(var1,bias1,mse1))
plot(1:5,
mse1,
main = "test case: x=10",
col = "green",
ylim = ylim1,
type = "1",
lwd = 2,
ylab = "",
xlab = "Degree")
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,bias1,mse1),max(var1,bias1,mse1))
plot(1:5,
mse1,
main = "test case: x=10",
col = "green",
ylim = ylim1,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
line(1:5,bias1,lwd=2,col="blue")
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,bias1,mse1),max(var1,bias1,mse1))
plot(1:5,
mse1,
main = "test case: x=10",
col = "green",
ylim = ylim1,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,bias1,lwd=2,col="blue")
lines(1:5,var1,lwd=2,col="red")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("green","red","blue"),
cex=.5)
plot(1:5,
mse2,
main = "test case: x=16",
col = "green",
ylim = ylim2,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,bias1,mse1),max(var1,bias1,mse1))
plot(1:5,
mse1,
main = "test case: x=10",
col = "green",
ylim = ylim1,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,bias1,lwd=2,col="blue")
lines(1:5,var1,lwd=2,col="red")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("green","red","blue"),
cex=.5)
# when x_0 = 16
ylim2<-c(min(var2,bias2,mse2),max(var2,bias2,mse2))
plot(1:5,
mse2,
main = "test case: x=16",
col = "green",
ylim = ylim2,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,bias2,lwd=2,col="blue")
lines(1:5,var2,lwd=2,col="red")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("green","red","blue"),
cex=.5)
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,bias1,mse1),max(var1,bias1,mse1))
plot(1:5,
mse1,
main = "Plot as function of poly degrees (x0=10)",
col = "green",
ylim = ylim1,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,bias1,lwd=2,col="blue")
lines(1:5,var1,lwd=2,col="red")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("green","red","blue"),
cex=.5)
# when x_0 = 16
ylim2<-c(min(var2,bias2,mse2),max(var2,bias2,mse2))
plot(1:5,
mse2,
main = "Plot as function of poly degrees (x0=16)",
col = "grey",
ylim = ylim2,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,var2,lwd=2,col="orange")
lines(1:5,bias2,lwd=2,col="purple")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("grey","orange","purple"),
cex=.5)
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,bias1,mse1),max(var1,bias1,mse1))
plot(1:5,
mse1,
main = "Plot as function of poly degrees (x0=10)",
col = "grey",
ylim = ylim1,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,var1,lwd=2,col="orange")
lines(1:5,bias1,lwd=2,col="purple")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("grey","orange","purple"),
cex=.5)
# when x_0 = 16
ylim2<-c(min(var2,bias2,mse2),max(var2,bias2,mse2))
plot(1:5,
mse2,
main = "Plot as function of poly degrees (x0=16)",
col = "grey",
ylim = ylim2,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,var2,lwd=2,col="orange")
lines(1:5,bias2,lwd=2,col="purple")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("grey","orange","purple"),
cex=.5)
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,sq_bias1,mse1),max(var1,sq_bias1,mse1))
# Solution goes here -----------
var1<-c(0,0,0,0,0)
var2<-c(0,0,0,0,0)
sq_bias1<-c(0,0,0,0,0)
sq_bias2<-c(0,0,0,0,0)
mse1<-c(0,0,0,0,0)
mse2<-c(0,0,0,0,0)
for (i in 1:5) {
var1[i]<-var(mat.pred.1[,i])
var2[i]<-var(mat.pred.2[,i])
sq_bias1[i]<-(mean(mat.pred.1[,i])-true.f(10))^2
sq_bias2[i]<-(mean(mat.pred.2[,i])-true.f(16))^2
mse1[i]<-sum((y.test.mat[,1]-mat.pred.1[,i])^2)/1000
mse2[i]<-sum((y.test.mat[,2]-mat.pred.2[,i])^2)/1000
}
var1
var2
sq_bias1
sq_bias2
mse1
mse2
# Solution goes here -----------
# when x_0 = 10
ylim1<-c(min(var1,sq_bias1,mse1),max(var1,sq_bias1,mse1))
plot(1:5,
mse1,
main = "Plot as function of poly degrees (x0=10)",
col = "grey",
ylim = ylim1,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,var1,lwd=2,col="orange")
lines(1:5,sq_bias1,lwd=2,col="purple")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("grey","orange","purple"),
cex=.5)
# when x_0 = 16
ylim2<-c(min(var2,sq_bias2,mse2),max(var2,sq_bias2,mse2))
plot(1:5,
mse2,
main = "Plot as function of poly degrees (x0=16)",
col = "grey",
ylim = ylim2,
type = "l",
lwd = 2,
ylab = "",
xlab = "Degree")
lines(1:5,var2,lwd=2,col="orange")
lines(1:5,sq_bias2,lwd=2,col="purple")
legend("topleft",
legend=c("MSE","Variance","Squared Bias"),
fill=c("grey","orange","purple"),
cex=.5)
